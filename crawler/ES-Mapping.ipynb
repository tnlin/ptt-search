{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "import re\n",
    "\n",
    "def parse_date(date):\n",
    "    if len(date.split('.')) > 1 :\n",
    "        dates = date.split(' ')\n",
    "        dates[1] = re.sub(\"\\D\", \"\", dates[1])\n",
    "        dates[3] = dates[3].split('.')[0]\n",
    "        date = \" \".join(dates)\n",
    "        date = datetime.strptime(date, '%B %d %Y, %H:%M:%S')\n",
    "    else:\n",
    "        date = date[date.find(\" \")+1:]\n",
    "        date = datetime.strptime(date, '%b %d %H:%M:%S %Y')\n",
    "\n",
    "    tzinfo = tz.gettz('Asia/Taipei')\n",
    "    return date.replace(tzinfo=tzinfo).isoformat()\n",
    "\n",
    "dates = [\n",
    "    'December 9th 2016, 22:24:35.000',\n",
    "    'Wed Oct 5 20:53:22 2016'\n",
    "]\n",
    "[parse_date(date) for date in dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assggy'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = 'assggy (IamCarmelo)'\n",
    "author.split(\" \")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "# url = 'https://www.ptt.cc/bbs/Beauty/M.1528654347.A.4DE.html'\n",
    "url = 'https://www.ptt.cc/bbs/LoL/M.1528721007.A.53B.html'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_img_url(main_content):\n",
    "    rule = '(?:http\\:|https\\:)?\\/\\/.*\\.(?:png|jpe?g|gif)'\n",
    "    items = main_content.find_all('a')\n",
    "    if items:\n",
    "        for item in items:\n",
    "            url = re.findall(rule, item['href'])\n",
    "            if url:\n",
    "                return url[0]\n",
    "\n",
    "\n",
    "main_content = soup.find(id=\"main-content\")\n",
    "parse_img_url(main_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping (PTT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import connections, DocType, Date, Nested, InnerDoc, Keyword, Text, Ip, Integer\n",
    "from datetime import datetime\n",
    "# connections.create_connection(hosts=['13.78.14.166'])\n",
    "connections.create_connection(hosts=['168.62.50.20'])\n",
    "\n",
    "class Message(InnerDoc):\n",
    "    push_tag = Keyword(ignore_above=256)\n",
    "    push_userid = Keyword(ignore_above=256)\n",
    "    push_content = Keyword(ignore_above=256)\n",
    "    push_ipdatetime = Keyword(ignore_above=256)\n",
    "\n",
    "class Article(DocType):\n",
    "    article_id = Keyword(ignore_above=256)\n",
    "    article_title = Text(\n",
    "        analyzer='ik_max_word',\n",
    "        search_analyzer = 'ik_max_word'\n",
    "    )\n",
    "    author = Keyword(ignore_above=256)\n",
    "    board = Keyword(ignore_above=256)\n",
    "    content = Text(\n",
    "        analyzer='ik_max_word',\n",
    "        search_analyzer = 'ik_max_word'\n",
    "    )\n",
    "    date = Keyword(ignore_above=256)\n",
    "    \n",
    "    messages = Nested(Message)\n",
    "    message_all = Integer()\n",
    "    message_count = Integer()\n",
    "    message_controversial = Integer()\n",
    "    message_push = Integer()\n",
    "    message_boo = Integer()\n",
    "    message_neutral = Integer()\n",
    "    \n",
    "    author_parsed = Keyword(ignore_above=256)\n",
    "    img_url = Keyword(ignore_above=256)\n",
    "    date_parsed = Date(default_timezone='Asia/Taipei')\n",
    "    ip = Keyword(ignore_above=256)\n",
    "\n",
    "    class Meta:\n",
    "        index = 'ptt-2018-06'\n",
    "        doc_type = 'article'\n",
    "\n",
    "Article.init()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from elasticsearch_dsl import Search\n",
    "# connections.create_connection(hosts=['13.78.14.166'])\n",
    "# client = Elasticsearch()\n",
    "# s = Search(index=\"test2-2018-06\") \\\n",
    "#     .filter(\"term\", category=\"search\") \\\n",
    "#     .query(\"match\", title=\"感情\")   \\\n",
    "#     .exclude(\"match\", description=\"父母\")\n",
    "\n",
    "# s.aggs.bucket('per_tag', 'terms', field='tags') \\\n",
    "#     .metric('max_lines', 'max', field='lines')\n",
    "# response = s.execute()\n",
    "# for hit in response:\n",
    "#     print(hit.meta.score, hit.title)\n",
    "# for tag in response.aggregations.per_tag.buckets:\n",
    "#     print(tag.key, tag.max_lines.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.233568 [新聞] 西瓜也有身份證了 後龍西瓜節週六熱鬧登\n",
      "11.233568 [新聞] 西瓜也有身份證了 後龍西瓜節週六熱鬧登\n",
      "11.217221 [問卦] 有紅西瓜的西瓜汁 為什麼沒小玉西瓜汁？\n",
      "11.177635 [新聞] 〈中部〉福興西瓜節週日登場 三選將齊促\n",
      "11.175111 [問卦] 有紅西瓜的西瓜汁 為什麼沒小玉西瓜汁？\n",
      "11.174166 Re: [問卦] 溪州有什麼特產啊\n",
      "11.173001 Re: [問卦] 溪州有什麼特產啊\n",
      "11.14826 [新聞] 〈中部〉福興西瓜節週日登場 三選將齊促\n",
      "11.067176 Re: [新聞] 【選情初探】民進黨：攻下台北、新北　就\n",
      "11.065167 Re: [新聞] 【選情初探】民進黨：攻下台北、新北　就\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch_dsl import Search, connections\n",
    "connections.create_connection(hosts=['13.78.14.166'])\n",
    "board = \"Boy-Girl\"\n",
    "board = \"Gossiping\"\n",
    "\n",
    "# Term 精确\n",
    "# Match 模糊\n",
    "s = Search(index=\"test-2018-06\") \\\n",
    "    .filter(\"term\", board=board) \\\n",
    "    .query(\"match\", content=\"西瓜\")   \\\n",
    "#     .query(\"match\", article_title=\"西瓜 夏天\")\\\n",
    "#     .exclude(\"match\", article_title=\"照片\")\n",
    "\n",
    "response = s.execute()\n",
    "for hit in response:\n",
    "    print(hit.meta.score, hit.article_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Search, connections\n",
    "connections.create_connection(hosts=['13.78.14.166'])\n",
    "# board = \"Gossiping\"\n",
    "board = \"Boy-Girl\"\n",
    "s = Search(index=\"ptt-2018-06\") \\\n",
    "    .filter(\"term\", board=board) \\\n",
    "    .query(\"match\", article_title=\"哥哥\")  \\\n",
    "#     .query(\"match\", content=\"西瓜 夏天\")\\\n",
    "#     .exclude(\"match\", article_title=\"照片\")\n",
    "\n",
    "response = s.execute()\n",
    "for hit in response:\n",
    "    print(hit.message_count.count, hit.article_title, hit.author, hit.meta.score,  hit.date_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 [新聞] 西瓜也有身份證了 後龍西瓜節週六熱鬧登 qqq87112 (kaim) 12.909994 2018-06-05T15:20:50+08:00\n",
      "0 Re: [問卦] 溪州有什麼特產啊 kutkin (  ) 12.744474 2018-06-06T11:00:54+08:00\n",
      "19 [問卦] 西瓜的真實身份是？ ysc1213 (ysc) 12.708532 2018-01-23T10:45:04+08:00\n",
      "8 [問卦] 有紅西瓜的西瓜汁 為什麼沒小玉西瓜汁？ q0000000 (十方眾生皆蒙昧 道消魔長) 12.691474 2018-05-13T10:44:13+08:00\n",
      "4 [新聞] 〈中部〉福興西瓜節週日登場 三選將齊促 qqq87112 (kaim) 12.678584 2018-06-01T08:43:56+08:00\n",
      "1 Re: [新聞] 【選情初探】民進黨：攻下台北、新北　就 sunyeah (   湯元嗎) 12.550674 2018-05-20T23:55:46+08:00\n",
      "2 [問卦] 憾！小X百貨竟然沒賣西瓜刀？ Marzzze (Marzzze) 12.5249 2018-05-25T14:26:09+08:00\n",
      "4 [新聞] 國宴西瓜行情佳　花警啟動「護瓜專案」 gjsjhang (臺灣杉－Biang) 12.500449 2018-05-10T13:48:46+08:00\n",
      "3 [新聞] 馬英九叫賣西瓜 1顆1萬8800元助弱勢 cc9i (正直與善良) 12.471011 2018-05-19T18:26:17+08:00\n",
      "3 [新聞] 猥褻無極限！爆乳女模開腿露下體破西瓜　 zuvupa (阿嘉) 12.466688 2018-04-26T15:02:44+08:00\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch_dsl import Search, connections\n",
    "connections.create_connection(hosts=['13.78.14.166'])\n",
    "board = \"Boy-Girl\"\n",
    "board = \"Gossiping\"\n",
    "\n",
    "# Term 精确\n",
    "# Match 模糊\n",
    "s = Search(index=\"ptt-2018-06\") \\\n",
    "    .filter(\"term\", board=board) \\\n",
    "    .query(\"match\", content=\"西瓜\")   \\\n",
    "#     .query(\"match\", article_title=\"西瓜 夏天\")\\\n",
    "#     .exclude(\"match\", article_title=\"照片\")\n",
    "\n",
    "response = s.execute()\n",
    "for hit in response:\n",
    "    print(hit.message_count.count, hit.article_title, hit.author, hit.meta.score,  hit.date_parsed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Board Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_au = {\n",
    "    'Gossiping': 14896,\n",
    "    'NBA': 4938,\n",
    "    'Stock': 2951,\n",
    "    'C_Chat': 2755,\n",
    "    'Baseball': 2609,\n",
    "    'LoL': 1737,\n",
    "    'sex': 1471,\n",
    "    'WomenTalk': 1234,\n",
    "    'MobileComm': 1211,\n",
    "    'movie': 1079,\n",
    "    'Boy-Girl': 1062,\n",
    "    'marvel': 1035,\n",
    "    'PlayStation': 1032,\n",
    "    'BabyMother': 1005,\n",
    "    'Hearthstone': 981,\n",
    "    'car': 926,\n",
    "    'Japan_Travel': 897,\n",
    "    'Lifeismoney': 894,\n",
    "    'Tech_Job': 693,\n",
    "    'KoreaStar': 681,\n",
    "    'KR_Entertain': 663,\n",
    "    'Tennis': 636,\n",
    "    'Beauty': 618,\n",
    "    'marriage': 578,\n",
    "    'ToS': 552,\n",
    "    'e-shopping': 494,\n",
    "    'Tainan': 470,\n",
    "    'ONE_PIECE': 450,\n",
    "    'home-sale': 437,\n",
    "    'PC_Shopping': 434,\n",
    "    'Kaohsiung': 429,\n",
    "    'MakeUp': 411,\n",
    "    'studyteacher': 388,\n",
    "    'Steam': 369,\n",
    "    'joke': 359,\n",
    "    'NSwitch': 345,\n",
    "    'StupidClown': 342,\n",
    "    'BuyTogether': 320,\n",
    "    'japanavgirls': 310,\n",
    "    'Examination': 307,\n",
    "    'Japandrama': 304,\n",
    "    'KoreaDrama': 300,\n",
    "    'AllTogether': 292,\n",
    "    'Salary': 289,\n",
    "    'iOS': 264,\n",
    "    'creditcard': 263,\n",
    "    'Elephants': 263,\n",
    "    'PokemonGO': 258,\n",
    "    'BeautySalon': 258,\n",
    "    'MuscleBeach': 256,\n",
    "    'HatePolitics': 235,\n",
    "    'CFantasy': 232,\n",
    "    'TaichungBun': 205,\n",
    "    'CVS': 199,\n",
    "    'SportLottery': 195,\n",
    "    'HardwareSale': 193,\n",
    "    'GetMarry': 190,\n",
    "    'FATE_GO': 183,\n",
    "    'EAseries': 182,\n",
    "    'Option': 182,\n",
    "    'Aviation': 180,\n",
    "    'job': 180,\n",
    "    'Palmar_Drama': 177,\n",
    "    'WOW': 176,\n",
    "    'biker': 175,\n",
    "    'BTS': 173,\n",
    "    'Hsinchu': 171,\n",
    "    'TaiwanDrama': 171,\n",
    "    'YuanChuang': 164,\n",
    "    'part-time': 163,\n",
    "    'TypeMoon': 162,\n",
    "    'PuzzleDragon': 158,\n",
    "    'Headphone': 155,\n",
    "    'Gamesale': 154,\n",
    "    'PathofExile': 153,\n",
    "    'KanColle': 151,\n",
    "    'FITNESS': 145,\n",
    "    'MLB': 143,\n",
    "    'Food': 141,\n",
    "    'TW_Entertain': 141,\n",
    "    'AC_In': 137,\n",
    "    'cat': 137,\n",
    "    'TWICE': 137,\n",
    "    'RealmOfValor': 135,\n",
    "    'DSLR': 134,\n",
    "    'Soft_Job': 133,\n",
    "    'basketballTW': 128,\n",
    "    'Wanted': 124,\n",
    "    'KoreanPop': 123,\n",
    "    'LGBT_SEX': 118,\n",
    "    'Finance': 117,\n",
    "    'WorldCup': 117,\n",
    "    'lesbian': 117,\n",
    "    'GBF': 115,\n",
    "    'HelpBuy': 114,\n",
    "    'NBA_Film': 114,\n",
    "    'mobilesales': 108,\n",
    "    'CN_Entertain': 107,\n",
    "    'IdolMaster': 105,\n",
    "    'Teacher': 105,\n",
    "    'Monkeys': 105,\n",
    "    'MH': 98,\n",
    "    'Zastrology': 98,\n",
    "    'XBOX': 97,\n",
    "    'CarShop': 96,\n",
    "    'DMM_GAMES': 94,\n",
    "    'TY_Research': 93,\n",
    "    'cookclub': 93,\n",
    "    'Isayama': 92,\n",
    "    'Guardians': 92,\n",
    "    'MacShop': 90,\n",
    "    'G-S-WARRIORS': 89,\n",
    "    'PublicServan': 87,\n",
    "    'Gov_owned': 86,\n",
    "    'DigiCurrency': 85,\n",
    "    'feminine_sex': 84,\n",
    "    'Lineage': 83,\n",
    "    'nb-shopping': 82,\n",
    "    'BabyProducts': 79,\n",
    "    'Korea_Travel': 78,\n",
    "    'AKB48': 78,\n",
    "    'Shadowverse': 77,\n",
    "    'FORMULA1': 75,\n",
    "    'Bank_Service': 74,\n",
    "    'DC_SALE': 73,\n",
    "    'Oversea_Job': 71,\n",
    "    'Railway': 71,\n",
    "    'Brand': 71,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = []\n",
    "size =  sum([v for k, v in board_au.items()]) // 8\n",
    "\n",
    "buffers = []\n",
    "buffer = 0\n",
    "for k, v in board_au.items():\n",
    "    buffer += v\n",
    "    buffers.append(k)\n",
    "    if buffer>size:\n",
    "        boards.append(buffers)\n",
    "        buffers = []\n",
    "        buffer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Gossiping'],\n",
       " ['NBA', 'Stock', 'C_Chat'],\n",
       " ['Baseball', 'LoL', 'sex', 'WomenTalk', 'MobileComm'],\n",
       " ['movie',\n",
       "  'Boy-Girl',\n",
       "  'marvel',\n",
       "  'PlayStation',\n",
       "  'BabyMother',\n",
       "  'Hearthstone',\n",
       "  'car',\n",
       "  'Japan_Travel',\n",
       "  'Lifeismoney'],\n",
       " ['Tech_Job',\n",
       "  'KoreaStar',\n",
       "  'KR_Entertain',\n",
       "  'Tennis',\n",
       "  'Beauty',\n",
       "  'marriage',\n",
       "  'ToS',\n",
       "  'e-shopping',\n",
       "  'Tainan',\n",
       "  'ONE_PIECE',\n",
       "  'home-sale',\n",
       "  'PC_Shopping',\n",
       "  'Kaohsiung',\n",
       "  'MakeUp',\n",
       "  'studyteacher',\n",
       "  'Steam'],\n",
       " ['joke',\n",
       "  'NSwitch',\n",
       "  'StupidClown',\n",
       "  'BuyTogether',\n",
       "  'japanavgirls',\n",
       "  'Examination',\n",
       "  'Japandrama',\n",
       "  'KoreaDrama',\n",
       "  'AllTogether',\n",
       "  'Salary',\n",
       "  'iOS',\n",
       "  'creditcard',\n",
       "  'Elephants',\n",
       "  'PokemonGO',\n",
       "  'BeautySalon',\n",
       "  'MuscleBeach',\n",
       "  'HatePolitics',\n",
       "  'CFantasy',\n",
       "  'TaichungBun',\n",
       "  'CVS',\n",
       "  'SportLottery',\n",
       "  'HardwareSale',\n",
       "  'GetMarry',\n",
       "  'FATE_GO',\n",
       "  'EAseries',\n",
       "  'Option',\n",
       "  'Aviation',\n",
       "  'job',\n",
       "  'Palmar_Drama',\n",
       "  'WOW',\n",
       "  'biker',\n",
       "  'BTS',\n",
       "  'Hsinchu',\n",
       "  'TaiwanDrama',\n",
       "  'YuanChuang']]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
